{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6e0e3f3-bd9f-4fc0-ae4f-bf6ce58de065",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# ReAct Agent Implementation\n",
    "\n",
    "## Overview\n",
    "In this example we will guide you through how to create a ReAct (Reasoning and Acting) agent implementation using Strands default orchestration. We will demonstrate a single-agent system that combines reasoning with direct tool execution, providing a baseline for comparison with multi-agent orchestration patterns. This notebook also serves as an introduction to TauBench tools and dataset for airline customer service scenarios.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./images/react.png\" alt=\"ReAct Agent Architecture\" width=\"600\">\n",
    "    <p>The system consists of a single agent that handles both reasoning and action:</p>\n",
    "    <p><em>ReAct Architecture: User Query → [ReAct Agent] → Final Response</em></p>\n",
    "</div>\n",
    "\n",
    "## Key Features\n",
    "\n",
    "* **Default Strands orchestration**: Uses built-in agent orchestration without custom multiagent graphs\n",
    "* **TauBench integration**: Demonstrates airline tools and dataset usage for realistic scenarios\n",
    "* **Single-agent simplicity**: Direct reasoning-action loops without orchestration complexity\n",
    "* **Tool integration**: Full access to airline tools suite for comprehensive task handling\n",
    "* **Baseline comparison**: Provides performance baseline against multi-agent patterns\n",
    "\n",
    "## Agent Details\n",
    "<div style=\"float: left; margin-right: 20px;\">\n",
    "    \n",
    "|Feature             |Description                                        |\n",
    "|--------------------|---------------------------------------------------|\n",
    "|Native tools used   |Full airline tools suite (14 tools)             |\n",
    "|Custom tools created|None (uses existing MAbench/TauBench tools)      |\n",
    "|Agent Structure     |Single-agent with default Strands orchestration |\n",
    "|AWS services used   |Amazon Bedrock                                   |\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "Copy\n",
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab3252-fae8-4150-b4f6-aa7fc189177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -r ./requirements.txt --quiet \n",
    "!pip3 install strands-agents==v1.6.0 strands-agents-tools==v0.2.5 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17b44fd-e882-433e-9c84-96c6659742b5",
   "metadata": {},
   "source": [
    "## Importing dependency packages\n",
    "\n",
    "Now let's import all the necessary libraries and modules for our Reflexion implementation. This includes standard Python libraries, AWS SDK components, Strands framework modules, and custom helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b126af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import sys\n",
    "sys.path.append('../data/ma-bench/')\n",
    "sys.path.append('../data/tau-bench/')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "# Strands imports\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "from strands.multiagent import GraphBuilder\n",
    "\n",
    "from strands.multiagent.graph import GraphBuilder\n",
    "from strands.agent import AgentResult\n",
    "from strands.types.content import Message\n",
    "from strands.types.streaming import StopReason\n",
    "from strands.telemetry.metrics import EventLoopMetrics\n",
    "from strands.telemetry.config import StrandsTelemetry\n",
    "import uuid\n",
    "import base64\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bedf0b4-d364-4507-b8de-7457a5810fd6",
   "metadata": {},
   "source": [
    "## Import airline domain tools\n",
    "\n",
    "Now we'll import the comprehensive set of airline domain tools from MAbench and TauBench. These tools provide the actual functionality that our ReAct agent will execute, including flight booking, reservation management, and customer service operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aadba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mabench.environments.airline.tools.book_reservation import book_reservation\n",
    "from mabench.environments.airline.tools.calculate import calculate\n",
    "from mabench.environments.airline.tools.cancel_reservation import cancel_reservation\n",
    "from mabench.environments.airline.tools.get_reservation_details import get_reservation_details\n",
    "from mabench.environments.airline.tools.get_user_details import get_user_details\n",
    "from mabench.environments.airline.tools.list_all_airports import list_all_airports\n",
    "from mabench.environments.airline.tools.search_direct_flight import search_direct_flight\n",
    "from mabench.environments.airline.tools.search_onestop_flight import search_onestop_flight\n",
    "from mabench.environments.airline.tools.send_certificate import send_certificate\n",
    "from mabench.environments.airline.tools.think import think\n",
    "from mabench.environments.airline.tools.transfer_to_human_agents import transfer_to_human_agents\n",
    "from mabench.environments.airline.tools.update_reservation_baggages import update_reservation_baggages\n",
    "from mabench.environments.airline.tools.update_reservation_flights import update_reservation_flights\n",
    "from mabench.environments.airline.tools.update_reservation_passengers import update_reservation_passengers\n",
    "\n",
    "domain = \"airline\"\n",
    "\n",
    "# from tau_bench.envs.tool import Tool\n",
    "# from tau_bench.envs.airline.tools import *\n",
    "from tau_bench.envs.airline.data import *\n",
    "from tau_bench.envs.airline.tasks import *\n",
    "from tau_bench.envs.airline.wiki import WIKI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7fdb02-0eb3-40e4-a4ef-e6df04efc748",
   "metadata": {},
   "source": [
    "## Configure Strands Framework\n",
    "\n",
    "Now let's set up the core Strands framework components that will power our ReAct  system. We need to configure the AWS Bedrock connection, conversation management, and logging to ensure our three-agent pipeline runs smoothly.\n",
    "\n",
    "### Framework Setup Process\n",
    "\n",
    "First, we'll establish the **AWS region** and create a `BedrockModel` instance that will be used by our agent. We do this so that all agents use the same LLM configuration for consistent behavior. \n",
    "\n",
    "Finally, we'll configure **logging** to minimize noise during execution so we can focus on the react execution flow and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1f104-4aa0-4451-a843-67c35526e151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create BedrockModel with specified region\n",
    "region=\"us-east-1\"\n",
    "bedrock_model_taubench = BedrockModel(region_name= region)\n",
    "\n",
    "#setup logging\n",
    "# Disable all logging except critical errors\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "# Silence specific noisy loggers completely\n",
    "for logger_name in [\"strands\", \"graph\", \"event_loop\", \"registry\", \"sliding_window_conversation_manager\", \"bedrock\", \"streaming\"]:\n",
    "    logging.getLogger(logger_name).setLevel(logging.CRITICAL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674e2e89-13a5-409d-9606-09691ea48700",
   "metadata": {},
   "source": [
    "## ReAct Agent Implementation\n",
    "\n",
    "Now let's implement the **ReAct (Reasoning and Acting) agent** that combines reasoning, tool execution, and response synthesis in a single agent loop. This represents the traditional approach where one agent handles all aspects of task completion through iterative think-act-observe cycles.\n",
    "\n",
    "### Airline Tools Configuration\n",
    "\n",
    "The ReAct agent has access to the complete suite of 14 airline domain tools, enabling it to handle any customer service scenario. We provide this comprehensive toolset so that the agent can directly execute booking operations, search flights, update reservations, and manage passenger information without requiring separate planning or execution phases.\n",
    "\n",
    "### System Prompt Design\n",
    "\n",
    "We will first create a specialized system prompt for airline customer service with specific instructions for handling geographic information and airport locations. We include policy guidance from the WIKI so that the agent understands airline business rules, fare classes, and operational constraints while maintaining helpful customer service behavior.\n",
    "\n",
    "The prompt emphasizes avoiding placeholder arguments and properly inferring U.S. state information for airports, ensuring accurate tool execution with real data rather than fabricated values.\n",
    "\n",
    "### ReAct Agent \n",
    "\n",
    "The `llm_react_agent()` function combines the system prompt, model configuration, and tool suite into a complete Strands Agent. This creates a single-agent system that can handle complex multi-step airline scenarios through ReAct's iterative reasoning process, providing a baseline for comparison with the orchestrated multi-agent patterns.\n",
    "\n",
    "The ReAct approach demonstrates direct tool execution with reasoning, where the agent autonomously decides which tools to call, when to call them, and how to synthesize the results into customer-friendly responses.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac56f733-604a-4e7d-a1ac-a31c91785323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    book_reservation,\n",
    "    calculate,\n",
    "    cancel_reservation,\n",
    "    get_reservation_details,\n",
    "    get_user_details,\n",
    "    list_all_airports,\n",
    "    search_direct_flight,\n",
    "    search_onestop_flight,\n",
    "    send_certificate,\n",
    "    think,\n",
    "    transfer_to_human_agents,\n",
    "    update_reservation_baggages,\n",
    "    update_reservation_flights,\n",
    "    update_reservation_passengers,\n",
    "]\n",
    "\n",
    "system_prompt_template = \"\"\"\n",
    "You are a helpful assistant for a travel website. Help the user answer any questions.\n",
    "\n",
    "<instructions>\n",
    "- Remeber to check if the the airport city is in the state mentioned by the user. For example, Houston is in Texas.\n",
    "- Infer about the the U.S. state in which the airport city resides. For example, Houston is in Texas.\n",
    "- You should not use made-up or placeholder arguments.\n",
    "<instructions>\n",
    "\n",
    "<policy>\n",
    "{policy}\n",
    "</policy>\n",
    "\"\"\"\n",
    "\n",
    "prompt = system_prompt_template.replace(\"{policy}\", WIKI)\n",
    "\n",
    "def llm_react_agent(tools):\n",
    "\n",
    "    return Agent( \n",
    "        model = bedrock_model_taubench, \n",
    "        tools = tools, \n",
    "        system_prompt = prompt,\n",
    "       \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60361654-f485-4182-bc43-d3e070b0f295",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Now let's load the **TauBench evaluation dataset** that contains real airline customer service scenarios. We do this so that we can test our ReAct agent against standardized benchmarks and measure its performance on authentic customer queries like:\n",
    "\n",
    "- Flight changes\n",
    "- Cancellations  \n",
    "- Booking modifications\n",
    "\n",
    "This loads the **single-turn airline tasks** from TauBench, which provides us with a collection of customer queries along with their expected outcomes for evaluation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403bc0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(\"..\", \"data\", \"tau-bench\", \"tau_bench\", \"envs\", f\"{domain}\", \"tasks_singleturn.json\")\n",
    "with open(output_path, \"r\") as file:\n",
    "    tasks = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba4dd89-f1c5-4353-8a92-e0180e881d70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def test_react_graph(task, question_id):\n",
    "    user_id = task['user_id']    \n",
    "    user_query= task[\"question\"]\n",
    "    print(user_query)    \n",
    "    agent = llm_react_agent(tools=tools)\n",
    "    start=time.time()\n",
    "    react_response = agent(user_query)    \n",
    "    exec_time=time.time()-start\n",
    "    print(f\" REACT execution time {exec_time} \\n\")\n",
    "    \n",
    "question_id = 0\n",
    "task = tasks[question_id]   \n",
    "test_react_graph(task, question_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e5fabd-ffea-4bc5-b4d9-279ff5528562",
   "metadata": {},
   "source": [
    "## Congrats!\n",
    "\n",
    "Congratulations! You've successfully created and tested a ReAct agent implementation using Strands default orchestration. This system demonstrates:\n",
    "\n",
    "- **Single-agent architecture** using Strands built-in orchestration for direct reasoning-action loops without custom multiagent complexity\n",
    "- **TauBench tools integration** with comprehensive airline tools suite (booking, search, updates) for real-world customer service scenarios\n",
    "- **Dataset exploration** using TauBench evaluation datasets to understand airline domain tasks and performance benchmarking\n",
    "- **Baseline performance** providing a foundation for comparing against more complex orchestration patterns\n",
    "\n",
    "The ReAct pattern excels at straightforward tasks requiring direct tool interaction and adaptive reasoning, making it ideal for simple airline queries and serving as a performance baseline. In the next notebooks, we will explore custom orchestration patterns like REWOO and Reflexion that build upon this foundation to handle more complex multi-step scenarios requiring specialized agent coordination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16979878-c758-4f9b-bcfe-f4d3f9acda81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
