{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "783c660e",
   "metadata": {},
   "source": [
    "# Reflexion Pattern Implementation with Strands Multiagent Graph\n",
    "\n",
    "## Overview\n",
    "\n",
    "This implementation demonstrates the **Reflexion pattern** using the Strands multiagent graph framework. Reflexion enables iterative self-improvement through reflection and revision, creating a quality-focused system that generates initial responses, critically evaluates them, and iteratively improves until reaching acceptable quality standards.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "The system consists of two specialized agents connected in a sequential graph with iterative feedback:\n",
    "\n",
    "```\n",
    "User Query → [Draft Agent] → [Revisor Agent] → Final Response\n",
    "                                    ↓\n",
    "                              Internal Loop\n",
    "                              (max 5 iterations)\n",
    "```\n",
    "\n",
    "### 1. Draft Agent\n",
    "- **Purpose**: Generates initial flight responses with built-in self-reflection\n",
    "- **Input**: User query (e.g., \"Change my flight to earlier time\")\n",
    "- **Output**: Initial response + reflection analysis + revision decision\n",
    "- **Implementation**: Custom agent class using `generate_initial_answer` tool\n",
    "\n",
    "### 2. Revisor Agent\n",
    "- **Purpose**: Iteratively improves responses based on reflection feedback\n",
    "- **Input**: Draft response + reflection analysis + original user query\n",
    "- **Process**: Uses internal loop to iterate revisions until quality threshold met or max iterations reached\n",
    "- **Output**: Final improved response after revision cycles\n",
    "- **Implementation**: Custom agent class with state management and `generate_revised_answer` tool\n",
    "\n",
    "## Key Technical Details\n",
    "\n",
    "### Custom Agent Classes\n",
    "Due to multiagent graph requirements, each agent extends the base `Agent` class with custom `stream_async()` methods:\n",
    "\n",
    "```python\n",
    "class DraftAgent(Agent):\n",
    "    async def stream_async(self, prompt: str):\n",
    "        result = self.tool.generate_initial_answer(query=prompt)\n",
    "        message = Message(content=[{\"text\": str(result)}])\n",
    "        agent_result = AgentResult(\n",
    "            stop_reason=\"end_turn\",\n",
    "            message=message,\n",
    "            metrics=EventLoopMetrics(),\n",
    "            state=None\n",
    "        )\n",
    "        yield {\"result\": agent_result}\n",
    "\n",
    "class RevisorAgent(Agent):\n",
    "    async def stream_async(self, input_data):\n",
    "        state = ReflexionState(**prev_state) if prev_state else ReflexionState()\n",
    "        \n",
    "        # Internal revision loop\n",
    "        while state.needs_revision and state.revision_count < state.max_iterations:\n",
    "            state.revision_count += 1\n",
    "            result = self.tool.generate_revised_answer(...)\n",
    "            # Update state with new response and reflection\n",
    "        \n",
    "        yield {\"result\": agent_result}\n",
    "```\n",
    "\n",
    "### Quality Assessment\n",
    "- **Multi-dimensional evaluation**: Completeness, clarity, actionability, user experience\n",
    "- **Query improvement**: Enhances prompts based on reflection feedback\n",
    "- **Error recovery**: Identifies and corrects incomplete responses\n",
    "\n",
    "## Usage\n",
    "\n",
    "```python\n",
    "# Create the reflexion multiagent graph\n",
    "reflexion_graph = create_reflexion_graph()\n",
    "\n",
    "# Execute with user query\n",
    "result = reflexion_graph(\n",
    "    \"I am Anya Garcia (ID: anya_garcia_5901). I booked flight 3RK2T9 and want to change passenger name from Mei Lee to Mei Garcia.\"\n",
    ")\n",
    "\n",
    "# Access results from each agent\n",
    "draft_result = result.results['draft']    # Initial response + reflection\n",
    "revisor_result = result.results['revisor']  # Final improved response\n",
    "```\n",
    "\n",
    "This implementation showcases how the Strands multiagent graph framework can implement self-improving AI systems that prioritize response quality through systematic reflection and iterative refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68566b50-ccba-4c9d-822e-7062fc6c07d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install -r ./requirements.txt --quiet --upgrade\n",
    "!pip3 install strands-agents strands-agents-tools --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6caacd-3fc8-4063-8763-a64e89a47b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import ipywidgets as widgets\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "import functools\n",
    "import requests\n",
    "import pytz\n",
    "import warnings\n",
    "from IPython.display import Image, display\n",
    "from botocore.config import Config\n",
    "from typing import Annotated, Literal, Optional, Union\n",
    "from typing_extensions import TypedDict\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, datetime\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "from strands import Agent\n",
    "from strands import tool\n",
    "from strands.models import BedrockModel\n",
    "from strands.agent.conversation_manager import SlidingWindowConversationManager\n",
    "\n",
    "from strands.multiagent.graph import GraphBuilder\n",
    "from strands.agent import AgentResult\n",
    "from strands.types.content import Message\n",
    "from strands.types.streaming import StopReason\n",
    "from strands.telemetry.metrics import EventLoopMetrics\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa4f23-579b-4c8d-9758-3f4d9bdfeadd",
   "metadata": {},
   "source": [
    "## Get MAbench and Taubench tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51405b31-e274-4a9a-9266-a9cb85077099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../data/ma-bench/')\n",
    "sys.path.append('../data/tau-bench/')\n",
    "\n",
    "from mabench.environments.airline.tools.book_reservation import book_reservation\n",
    "from mabench.environments.airline.tools.calculate import calculate\n",
    "from mabench.environments.airline.tools.cancel_reservation import cancel_reservation\n",
    "from mabench.environments.airline.tools.get_reservation_details import get_reservation_details\n",
    "from mabench.environments.airline.tools.get_user_details import get_user_details\n",
    "from mabench.environments.airline.tools.list_all_airports import list_all_airports\n",
    "from mabench.environments.airline.tools.search_direct_flight import search_direct_flight\n",
    "from mabench.environments.airline.tools.search_onestop_flight import search_onestop_flight\n",
    "from mabench.environments.airline.tools.send_certificate import send_certificate\n",
    "from mabench.environments.airline.tools.think import think\n",
    "from mabench.environments.airline.tools.transfer_to_human_agents import transfer_to_human_agents\n",
    "from mabench.environments.airline.tools.update_reservation_baggages import update_reservation_baggages\n",
    "from mabench.environments.airline.tools.update_reservation_flights import update_reservation_flights\n",
    "from mabench.environments.airline.tools.update_reservation_passengers import update_reservation_passengers\n",
    "\n",
    "domain = \"airline\"\n",
    "\n",
    "from tau_bench.envs.airline.data import *\n",
    "from tau_bench.envs.airline.tasks import *\n",
    "from tau_bench.envs.airline.wiki import WIKI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf713768-eb39-4046-94fe-de9a56538115",
   "metadata": {},
   "source": [
    "### Use Strands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea86c4-fe47-464b-8841-0ec3d2d6bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = \"us-east-1\"\n",
    "\n",
    "\n",
    "bedrock_model_taubench = BedrockModel(region_name=region)\n",
    "conv_manager = SlidingWindowConversationManager(window_size=10)\n",
    "\n",
    "# Disable logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "for logger_name in [\"strands\", \"graph\", \"event_loop\", \"registry\", \"sliding_window_conversation_manager\", \"bedrock\", \"streaming\"]:\n",
    "    logging.getLogger(logger_name).setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec72152c-bc50-4d40-952e-98db54c1cea3",
   "metadata": {},
   "source": [
    "## Reflexion with State Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcbdcd1-0c4d-4e72-9734-aaad86fdc7d5",
   "metadata": {},
   "source": [
    "## Define the Reflexion State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "state-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ReflexionState:\n",
    "    \"\"\"State for reflexion workflow\"\"\"\n",
    "    user_query: str = \"\"\n",
    "    response: str = \"\"\n",
    "    reflection: str = \"\"\n",
    "    needs_revision: bool = False\n",
    "    max_iterations: int = 5\n",
    "    revision_count: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4207d8b8-c4d2-42e0-a9ba-b24c72e4e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_prompt(prompt) -> str:\n",
    "    if isinstance(prompt, list):\n",
    "        # assume list of dicts like [{\"text\": \"...\"}]\n",
    "        texts = [p.get(\"text\", \"\") for p in prompt if isinstance(p, dict)]\n",
    "        return \" \".join(t.strip() for t in texts if t)\n",
    "    if isinstance(prompt, dict) and \"text\" in prompt:\n",
    "        return prompt[\"text\"].strip()\n",
    "    if isinstance(prompt, str):\n",
    "        return prompt.strip()\n",
    "    return str(prompt).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd4af57-5102-4e9e-956f-0b64f5c975b0",
   "metadata": {},
   "source": [
    "## Flight Tool Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea1a38-334a-40e8-879a-a354226a170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_template = \"\"\"\n",
    "You are a helpful assistant for a travel website. Help the user answer any questions.\n",
    "\n",
    "<instructions>\n",
    "-You MUST refer the <policy> to follow the guidelines to answer user question accurately\n",
    "- Remeber to check if the the airport city is in the state mentioned by the user. For example, Houston is in Texas.\n",
    "- Infer about the the U.S. state in which the airport city resides. For example, Houston is in Texas.\n",
    "- You should not use made-up or placeholder arguments.\n",
    "<instructions>\n",
    "\n",
    "<policy>\n",
    "{policy}\n",
    "</policy>\n",
    "\"\"\"\n",
    "\n",
    "prompt = system_prompt_template.replace(\"{policy}\", WIKI)\n",
    "\n",
    "\n",
    "class FlightToolExecutor(Agent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            model=bedrock_model_taubench,\n",
    "            system_prompt=prompt,\n",
    "            tools=[\n",
    "                book_reservation, calculate, cancel_reservation, get_reservation_details,\n",
    "                get_user_details, list_all_airports, search_direct_flight, search_onestop_flight,\n",
    "                send_certificate, think, transfer_to_human_agents, update_reservation_baggages,\n",
    "                update_reservation_flights, update_reservation_passengers\n",
    "            ]\n",
    "        )\n",
    "\n",
    "flight_executor = FlightToolExecutor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50db405-c76c-48a8-9dca-d5bf1323fbdf",
   "metadata": {},
   "source": [
    "### Draft Node with State Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2d9d6-da18-4cc2-9445-81e1ddc2fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_system_prompt=\"\"\"You are analyzing a flight assistant's response that uses real flight database tools.\n",
    "        \n",
    "IMPORTANT: The flight data comes from real database queries, NOT hallucination.\n",
    "        \n",
    "Analyze the response quality on these dimensions:\n",
    "1. **Completeness**: Does it address all parts of the user's query? \n",
    "2. **Final Answer**: If the user query clearly states the final goal and if it can be fulfiled as per the policy, then does the response show that?\n",
    "2. **Clarity**: Is the information presented clearly and logically?\n",
    "3. **Actionability**: Are next steps or options clearly presented?\n",
    "4. **User Experience**: Is the tone helpful and appropriate?\n",
    "5. **Missing Information**: What important details are missing?\n",
    "6. **Decision**: REVISE or ACCEPT\n",
    "7. **Reason**: Why this decision was made\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f81739-1fc4-4883-b363-1dc51a5064d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def generate_initial_answer(query: str) -> str:\n",
    "    \"\"\"Generate initial answer, reflect, and decide if revision needed\"\"\"\n",
    "    \n",
    "    flight_response = flight_executor(query)\n",
    "    answer_text = str(flight_response)\n",
    "    \n",
    "    reflection_agent = Agent(\n",
    "        model=bedrock_model_taubench,\n",
    "        system_prompt=reflection_system_prompt\n",
    "    )\n",
    "    \n",
    "    reflection_prompt = f\"\"\"\n",
    "Original Query: {query}\n",
    "Flight Assistant's Answer: {answer_text}\n",
    "\n",
    "Remember: The flight data comes from real database queries.\n",
    "Please provide a critical reflection of this answer:\"\"\"\n",
    "    \n",
    "    reflection_response = reflection_agent(reflection_prompt)\n",
    "    reflection_text = str(reflection_response)\n",
    "    \n",
    "    needs_revision = \"REVISE\" in reflection_text.upper()\n",
    "    \n",
    "    return f\"**Answer**: {answer_text}\\n**Self-Reflection**: {reflection_text}\\n**Needs Revision**: {needs_revision}\"\n",
    "\n",
    "class DraftAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            model=bedrock_model_taubench,\n",
    "            tools=[generate_initial_answer],\n",
    "            name=\"draft\",\n",
    "            description=\"Generates flight assistance answers with self-reflection\"\n",
    "        )\n",
    "    \n",
    "    async def stream_async(self, prompt: str):\n",
    "\n",
    "        prompt=normalize_prompt(prompt)        \n",
    "        result = self.tool.generate_initial_answer(query=prompt)        \n",
    "        extracted = extract_answer_reflection_revision(result)\n",
    "        \n",
    "        message = Message(content=[{\"text\": str(result)}])\n",
    "        print(\"DEBUG: REVISOR AGENT RESULT: \\n\", json.dumps(message), \"\\n\")\n",
    "        agent_result = AgentResult(\n",
    "            stop_reason=\"end_turn\",\n",
    "            message=message,\n",
    "            metrics=EventLoopMetrics(),\n",
    "            state=None #state.__dict__\n",
    "        )\n",
    "        yield {\"result\": agent_result}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4161a2e0-b17d-40f3-a4c5-1a12bba170e7",
   "metadata": {},
   "source": [
    "## Revisor Agent with State Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633d6ef2-e393-4794-b091-e30e59e53e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_improver_system_prompt=\"\"\"You are a query improvement specialist. Based on reflection analysis, improve the original user query to address identified issues and guide better responses.\n",
    "\n",
    "Examples:\n",
    "Original: \"Book me a flight from NYC to LA tomorrow\"\n",
    "Issue: \"Agent booked immediately without showing options\"\n",
    "Improved: \"Please SEARCH and SHOW ME available flight options from NYC to LA tomorrow. I want to see different times, prices, and airlines before deciding. DO NOT book anything until I confirm.\"\n",
    "\n",
    "Now improve the provided query based on the specific reflection issues identified.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba5a6e-a169-4ecd-abab-f2ad299723af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_answer_reflection_revision(tool_result):\n",
    "    content_text = tool_result[\"content\"][0][\"text\"]\n",
    "\n",
    "    answer_match = re.search(r\"\\*\\*Answer\\*\\*:(.*?)(?=\\*\\*Self-Reflection\\*\\*:)\", content_text, re.DOTALL)\n",
    "    answer = answer_match.group(1).strip() if answer_match else \"[Not found]\"\n",
    "\n",
    "    reflection_match = re.search(r\"\\*\\*Self-Reflection\\*\\*:(.*?)(?=\\*\\*Needs Revision\\*\\*:|$)\", content_text, re.DOTALL)\n",
    "    self_reflection = reflection_match.group(1).strip() if reflection_match else \"[Not found]\"\n",
    "\n",
    "    revision_match = re.search(r\"\\*\\*Needs Revision\\*\\*:\\s*(True|False)\", content_text)\n",
    "    needs_revision = revision_match.group(1) == \"True\" if revision_match else False\n",
    "\n",
    "    query_match = re.search(r\"\\*\\*User-Query\\*\\*:\\s*(.*?)(?=\\n|$)\", content_text)\n",
    "    query = query_match.group(1).strip() if query_match else \"[Not found]\"\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"self_reflection\": self_reflection,\n",
    "        \"needs_revision\": needs_revision,\n",
    "        \"user_query\": query\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c56241-d51f-4472-9123-c9f6b6ef6b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def generate_revised_answer(current_user_query, current_response=\"\", current_reflection=\"\") -> str:\n",
    "    \"\"\"Generate revised answer, reflect, and decide if further revision needed\"\"\"\n",
    "    \n",
    "    query_improver = Agent(\n",
    "        model=bedrock_model_taubench,\n",
    "        system_prompt=query_improver_system_prompt\n",
    "    )\n",
    "    \n",
    "    improved_query = query_improver(f\"Current user query: {current_user_query}\\nCurrent Response: {current_response}\\nReflection: {current_reflection}\\nCreate better query:\")\n",
    "    \n",
    "    flight_response = flight_executor(str(improved_query))\n",
    "    revised_answer = str(flight_response)\n",
    "    \n",
    "    revision_reflection_agent = Agent(\n",
    "        model=bedrock_model_taubench,\n",
    "        system_prompt=reflection_system_prompt\n",
    "    )\n",
    "    \n",
    "    new_reflection = revision_reflection_agent(f\"Task: {current_user_query} Revised Answer: {revised_answer} Analyze and decide:\")\n",
    "    reflection_text = str(new_reflection)\n",
    "    \n",
    "    needs_revision = \"REVISE\" in reflection_text.upper()\n",
    "    \n",
    "    return f\"\\n**User-Query**: {current_user_query}\\n**Answer**: {revised_answer}\\n**Self-Reflection**: {reflection_text}\\n**Needs Revision**: {needs_revision}\"\n",
    "\n",
    "class RevisorAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            model=bedrock_model_taubench,\n",
    "            tools=[generate_revised_answer],\n",
    "            name=\"revisor\",\n",
    "            description=\"Revises flight responses\"\n",
    "        )\n",
    "\n",
    "    async def stream_async(self, input_data):\n",
    "        input_data=normalize_prompt(input_data)  \n",
    "        if isinstance(input_data, str):\n",
    "            state = ReflexionState(user_query=input_data)\n",
    "        else:\n",
    "            prev_state = getattr(input_data, 'state', {}) or {}\n",
    "            print(f\"PREV STATE FROM REVIOSR: {prev_state} \\n\")\n",
    "            state = ReflexionState(**prev_state) if prev_state else ReflexionState()\n",
    "\n",
    "        # Extract draft agent result\n",
    "        draft_start = input_data.find('From draft:')\n",
    "        if draft_start != -1:\n",
    "            draft_content = input_data[draft_start + len('From draft:'):].strip()\n",
    "            # Parse the draft result\n",
    "            extracted = extract_answer_reflection_revision({'content': [{'text': draft_content}]})\n",
    "            draft_response = extracted['answer']\n",
    "            draft_reflection = extracted['self_reflection']\n",
    "            needs_revision = extracted['needs_revision']\n",
    "\n",
    "        state = ReflexionState(\n",
    "            user_query=user_query,\n",
    "            response=draft_response,\n",
    "            reflection=draft_reflection,\n",
    "            needs_revision=needs_revision,\n",
    "            revision_count=0,\n",
    "            max_iterations=5\n",
    "        )\n",
    "        \n",
    "        print(f\"Revisor starting: revision_count={state.revision_count}, needs_revision={state.needs_revision}\")\n",
    "        \n",
    "        if state.needs_revision and state.revision_count < state.max_iterations:\n",
    "            state.revision_count += 1\n",
    "            \n",
    "            result = self.tool.generate_revised_answer(\n",
    "                current_user_query=state.user_query,\n",
    "                current_response=state.response,\n",
    "                current_reflection=state.reflection\n",
    "            )\n",
    "            \n",
    "            extracted = extract_answer_reflection_revision(result)\n",
    "            state.response = extracted[\"answer\"]\n",
    "            state.reflection = extracted[\"self_reflection\"]\n",
    "            state.needs_revision = extracted[\"needs_revision\"]\n",
    "        else:\n",
    "            result = f\"**Answer**: {state.response}\\n**Final Reflection**: {state.reflection}\\n**Revision Complete**: After {state.revision_count} revisions\"\n",
    "        \n",
    "        message = Message(content=[{\"text\": str(result)}])\n",
    "        print(\"DEBUG: REVISOR AGENT RESULT: \\n\", json.dumps(message), \"\\n\")\n",
    "        agent_result = AgentResult(\n",
    "            stop_reason=\"end_turn\",\n",
    "            message=message,\n",
    "            metrics=EventLoopMetrics(),\n",
    "            state=state.__dict__\n",
    "        )\n",
    "        yield {\"result\": agent_result}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d8463c-09f9-4433-92ba-1663a83798c5",
   "metadata": {},
   "source": [
    "## Build Reflexion Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40521cd2-b8c6-4aa3-a0b6-742830d054cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands.multiagent.graph import GraphBuilder, GraphState\n",
    "\n",
    "def create_reflexion_graph():\n",
    "    \"\"\"Create reflexion graph with state management\"\"\"\n",
    "    \n",
    "    draft_agent = DraftAgent()\n",
    "    revisor_agent = RevisorAgent()\n",
    "    \n",
    "    builder = GraphBuilder()\n",
    "    \n",
    "    draft_node = builder.add_node(draft_agent, \"draft\")\n",
    "    revisor_node = builder.add_node(revisor_agent, \"revisor\")\n",
    "    \n",
    "    builder.add_edge(draft_node, revisor_node)\n",
    "    builder.set_entry_point(\"draft\")\n",
    "    \n",
    "    return builder.build()\n",
    "\n",
    "reflexion_graph = create_reflexion_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6cebc9-f9cc-43c5-a9fa-7d53dd79b059",
   "metadata": {},
   "source": [
    "## Execute Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02191e41-e024-4355-8ecd-6c24606fab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(\"..\", \"data\", \"tau-bench\", \"tau_bench\", \"envs\", f\"{domain}\", \"tasks_singleturn.json\")\n",
    "with open(output_path, \"r\") as file:\n",
    "    tasks = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10459f3-1830-4f91-afd9-ad03e69de189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reflexion_graph(user_query):\n",
    "    reflexion_graph = create_reflexion_graph()\n",
    "    \n",
    "    print(\"=== Testing Reflexion Graph ===\")\n",
    "    print(f\"Test Prompt: {user_query}\")\n",
    "    print(\"\\n--- Executing Graph ---\")\n",
    "    start= time.time()\n",
    "    result = reflexion_graph(user_query)\n",
    "    exec_time= time.time()-start\n",
    "    print(f\"\\n EXEC Time: {exec_time}\")\n",
    "    print(f\"\\nGraph Status: {result.status}\")\n",
    "    print(f\"Total Nodes: {result.total_nodes}\")\n",
    "    print(f\"Completed Nodes: {result.completed_nodes}\")\n",
    "    print(f\"Execution Order: {[node.node_id for node in result.execution_order]}\")\n",
    "    \n",
    "    print(\"\\n--- Node Results ---\")\n",
    "    for node_id, node_result in result.results.items():\n",
    "        print(f\"\\n{node_id.upper()}:\")\n",
    "        print(f\"Status: {node_result.status}\")\n",
    "        if hasattr(node_result, 'result') and node_result.result:\n",
    "            print(f\"Result: {str(node_result.result)}...\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ebb91",
   "metadata": {},
   "source": [
    "### Test with a particular question_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e397b453-5fb9-4263-8136-d25795d55b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "question_id = 43\n",
    "task = tasks[question_id]\n",
    "user_query = task[\"question\"]\n",
    "print(user_query)\n",
    "\n",
    "reflexion_response = test_reflexion_graph(user_query)\n",
    "# Save to file with question ID suffix\n",
    "filename = f\"./output/reflexion_response_{question_id}.txt\"\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(str(reflexion_response))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
